{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/matth/Documents/ETHZ/01_DS/02_HS23/02_DeepLearning/03_Project/00_Testbed_DL/scaling_mlps_mirror')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# MLP model\n",
    "from data_utils.data_stats import *\n",
    "from models.networks import *\n",
    "from utils.download import *\n",
    "\n",
    "# CNN model\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Others\n",
    "from tqdm import tqdm\n",
    "from data_utils.data_stats import *\n",
    "import torchvision.transforms as T\n",
    "import random\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load standard mlp model\n",
    "dataset = 'imagenet'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'        #'B_6-Wi_512'         #'B_12-Wi_1024'  'B-12_Wi-1024_res_64_imagenet_epochs_50'   \n",
    "resolution = 64                      # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "checkpoint = 'in21k_imagenet'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10\n",
    "model_mlp = get_model(architecture=architecture, resolution=resolution, num_classes=num_classes,\n",
    "                  checkpoint=checkpoint, load_device='cpu', dropout=False)\n",
    "model_mlp.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load CNN\n",
    "model_cnn = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "for param in model_cnn.parameters():\n",
    "    param.requires_grad = False\n",
    "#model_cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normalization constants\n",
    "MEAN = MEAN_DICT[\"imagenet\"]/255\n",
    "STD = STD_DICT[\"imagenet\"]/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define plot generating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def preprocess(img, size=224):\n",
    "    transform = T.Compose([\n",
    "        T.Scale(size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=MEAN.tolist(),\n",
    "                    std=STD.tolist()),\n",
    "        T.Lambda(lambda x: x[None]),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def deprocess(img, should_rescale=True):\n",
    "    transform = T.Compose([\n",
    "        T.Lambda(lambda x: x[0]),\n",
    "        T.Normalize(mean=[0, 0, 0], std=(1.0 / STD).tolist()),\n",
    "        T.Normalize(mean=(-MEAN).tolist(), std=[1, 1, 1]),\n",
    "        T.Lambda(rescale) if should_rescale else T.Lambda(lambda x: x),\n",
    "        T.ToPILImage(),\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "def rescale(x):\n",
    "    low, high = x.min(), x.max()\n",
    "    x_rescaled = (x - low) / (high - low)\n",
    "    return x_rescaled\n",
    "    \n",
    "def blur_image(X, sigma=1):\n",
    "    X_np = X.cpu().clone().numpy()\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=2)\n",
    "    X_np = gaussian_filter1d(X_np, sigma, axis=3)\n",
    "    X.copy_(torch.Tensor(X_np).type_as(X))\n",
    "    return X\n",
    "\n",
    "def jitter(X, ox, oy):\n",
    "    \"\"\"\n",
    "    Helper function to randomly jitter an image.\n",
    "    \n",
    "    Inputs\n",
    "    - X: PyTorch Tensor of shape (N, C, H, W)\n",
    "    - ox, oy: Integers giving number of pixels to jitter along W and H axes\n",
    "    \n",
    "    Returns: A new PyTorch Tensor of shape (N, C, H, W)\n",
    "    \"\"\"\n",
    "    #print(X.size())\n",
    "\n",
    "    if ox != 0:\n",
    "        left = X[:, :, :, :-ox]\n",
    "        right = X[:, :, :, -ox:]\n",
    "        X = torch.cat([right, left], dim=3)\n",
    "    if oy != 0:\n",
    "        top = X[:, :, :-oy]\n",
    "        bottom = X[:, :, -oy:]\n",
    "        X = torch.cat([bottom, top], dim=2)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_activation_maximization(target_y, model, dtype, model_type, **kwargs):\n",
    "    \"\"\"\n",
    "    Generate an image to maximize the score of target_y under a pretrained model.\n",
    "    \n",
    "    Inputs:\n",
    "    - target_y: Integer in the range [0, 1000) giving the index of the class\n",
    "    - model: A pretrained MLP that will be used to generate the image\n",
    "    - dtype: Torch datatype to use for computations\n",
    "    \n",
    "    Keyword arguments:\n",
    "    - l2_reg: Strength of L2 regularization on the image\n",
    "    - learning_rate: How big of a step to take\n",
    "    - num_iterations: How many iterations to use\n",
    "    - blur_every: How often to blur the image as an implicit regularizer\n",
    "    - max_jitter: How much to gjitter the image as an implicit regularizer\n",
    "    - show_every: How often to show the intermediate result\n",
    "    \"\"\"\n",
    "\n",
    "    assert (model_type in [\"cnn\", \"mlp\"]), \"Error: specified model type not implemented\"\n",
    "\n",
    "    #--------------\n",
    "    # Set the seed for random module\n",
    "    seed = 1 #42#1  \n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set the seed for numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Set the seed for PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    #--------------\n",
    "\n",
    "    ## Default parameter set\n",
    "    #model.type(dtype)\n",
    "    #l2_reg = kwargs.pop('l2_reg', 1e-3)\n",
    "    #learning_rate = kwargs.pop('learning_rate', 25)\n",
    "    #num_iterations = kwargs.pop('num_iterations', 200) #100\n",
    "    #blur_every = kwargs.pop('blur_every', 10)\n",
    "    #max_jitter = kwargs.pop('max_jitter', 16)\n",
    "    #show_every = kwargs.pop('show_every', 25)\n",
    "\n",
    "    # Tuned parameter sets\n",
    "    if model_type == \"mlp\":\n",
    "        model.type(dtype)\n",
    "        l2_reg = kwargs.pop('l2_reg', 1e-3)\n",
    "        learning_rate = kwargs.pop('learning_rate', 20)\n",
    "        num_iterations = kwargs.pop('num_iterations', 800) \n",
    "        blur_every = kwargs.pop('blur_every', 5)\n",
    "        max_jitter = kwargs.pop('max_jitter', 16)\n",
    "        show_every = kwargs.pop('show_every', 25)\n",
    "    elif model_type == \"cnn\":\n",
    "        model.type(dtype)\n",
    "        l2_reg = kwargs.pop('l2_reg', 1e-3)\n",
    "        learning_rate = kwargs.pop('learning_rate', 5)\n",
    "        num_iterations = kwargs.pop('num_iterations', 800) \n",
    "        blur_every = kwargs.pop('blur_every', 40)\n",
    "        max_jitter = kwargs.pop('max_jitter', 0)\n",
    "        show_every = kwargs.pop('show_every', 25)\n",
    "\n",
    "    # Randomly initialize the image as a PyTorch Tensor, and also wrap it in\n",
    "    # a PyTorch Variable.    \n",
    "    if model_type == \"mlp\":\n",
    "        img = torch.randn(1, 3, 64, 64).mul_(1.0).type(dtype)\n",
    "        img_reshaped = torch.reshape(img, (img.shape[0], -1))\n",
    "        img_var = Variable(img_reshaped, requires_grad=True)\n",
    "        original_shape = (img.shape[0], img.shape[1], 64, 64)\n",
    "        img_restored = img_reshaped.view(original_shape)\n",
    "    elif model_type == \"cnn\":\n",
    "        img = torch.randn(1, 3, 224, 224).mul_(1.0).type(dtype)\n",
    "        img_var = Variable(img, requires_grad=True)        \n",
    "\n",
    "    # Perform activation maximization\n",
    "    for t in range(num_iterations):\n",
    "        \n",
    "        # Randomly jitter the image a bit; this gives slightly nicer results\n",
    "        ox, oy = random.randint(0, max_jitter), random.randint(0, max_jitter)\n",
    "        if model_type == \"mlp\":\n",
    "            img_restored.copy_(jitter(img_restored, ox, oy))\n",
    "            img_reshaped = torch.reshape(img_restored, (img_restored.shape[0], -1))\n",
    "        elif model_type == \"cnn\":\n",
    "            img.copy_(jitter(img, ox, oy))\n",
    "\n",
    "        # Perform forward and backward pass\n",
    "        scores = model(img_var)\n",
    "        scores[:, target_y].backward()\n",
    "        \n",
    "        # Compute the regularized gradient and make an update step\n",
    "        if model_type == \"mlp\":\n",
    "            grad = img_var.grad.data - 2 * l2_reg * img_reshaped\n",
    "            img_reshaped += learning_rate * grad\n",
    "            img_restored = img_reshaped.view(original_shape)\n",
    "        elif model_type == \"cnn\":\n",
    "            grad = img_var.grad.data - 2 * l2_reg * img\n",
    "            img += learning_rate * grad\n",
    "        img_var.grad.data.zero_()\n",
    "\n",
    "        # Undo the random jitter\n",
    "        if model_type == \"mlp\":\n",
    "            img_restored.copy_(jitter(img_restored, -ox, -oy))\n",
    "            img_reshaped = torch.reshape(img_restored, (img_restored.shape[0], -1))\n",
    "        elif model_type == \"cnn\":\n",
    "            img.copy_(jitter(img, -ox, -oy))\n",
    "\n",
    "        # As regularizer, clamp the image and periodically blur the image\n",
    "        for c in range(3):\n",
    "            lo = float(-MEAN[c] / STD[c])\n",
    "            hi = float((1.0 - MEAN[c]) / STD[c])\n",
    "            if model_type == \"mlp\":\n",
    "                img_restored[:, c].clamp_(min=lo, max=hi)\n",
    "                img_reshaped = torch.reshape(img_restored, (img_restored.shape[0], -1))\n",
    "            elif model_type == \"cnn\":\n",
    "                img[:, c].clamp_(min=lo, max=hi)\n",
    "\n",
    "        # As regularizer, periodically blur the image\n",
    "        if t % blur_every == 0:\n",
    "            if model_type == \"mlp\":\n",
    "                img_restored = blur_image(img_restored, sigma=0.5)\n",
    "                img_reshaped = torch.reshape(img_restored, (img_restored.shape[0], -1))\n",
    "            elif model_type == \"cnn\":\n",
    "                blur_image(img, sigma=0.5)     \n",
    "\n",
    "        # Periodically show the image\n",
    "        if t == 0 or (t + 1) % show_every == 0 or t == num_iterations - 1:\n",
    "            if model_type == \"mlp\":\n",
    "                plt.imshow(deprocess(img_restored.clone().cpu()))\n",
    "            elif model_type == \"cnn\":\n",
    "                plt.imshow(deprocess(img.clone().cpu()))\n",
    "            plt.title('Iteration %d / %d' % (t + 1, num_iterations))\n",
    "            plt.gcf().set_size_inches(4, 4)\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "\n",
    "            # Specify the folder path where you want to save the plot\n",
    "            output_folder = './output_images'\n",
    "            # Ensure the output folder exists or create it if not\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "            # Save the plot to the specified folder\n",
    "            timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            output_filename = timestr + '.png'\n",
    "            output_filepath = os.path.join(output_folder, output_filename)\n",
    "            plt.savefig(output_filepath)\n",
    "    \n",
    "            plt.show()\n",
    "\n",
    "    if model_type == \"cnn\":\n",
    "        return deprocess(img.cpu())\n",
    "    elif model_type == \"mlp\":\n",
    "        return deprocess(img_restored.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate activation maximization images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define specific on figure\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model for activation maximization\n",
    "model = model_cnn # model_mlp #\n",
    "model_type = \"cnn\" # \"mlp\" # \n",
    "\n",
    "# Define target output\n",
    "target_y_arr = np.array([\n",
    "                         #404, # airliner (airplane)\n",
    "                         294, # brown bear (bear)\n",
    "                         #671, # mountain bike (bicycle)\n",
    "                         #15, # robin (bird)\n",
    "                         #814, # speedboat (boat)\n",
    "                         #440, # beer bottle (bottle)\n",
    "                         #817, # sports car (car)\n",
    "                         #284, # siamese cat (cat)\n",
    "                         559, # folding chair (chair)\n",
    "                         892, # wall clock (clock)\n",
    "                         #235, # german shepherd (dog)\n",
    "                         386, # african elephant (elephant)\n",
    "                         #508, # computer keyboard (keyboard)\n",
    "                         #623, # cleaver (knife)\n",
    "                         #766, # rotisserie (oven)\n",
    "                         #867 # trailer truck (truck)\n",
    "                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to use GPU\n",
    "model.type(dtype)\n",
    "\n",
    "for target_y in target_y_arr:\n",
    "    out = create_activation_maximization(target_y, model, dtype, model_type = model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
