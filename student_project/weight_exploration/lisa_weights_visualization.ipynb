{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m get_model\n",
      "File \u001b[0;32m~/Desktop/code_projects/dl_project/scaling_mlps_mirror/student_project/weight_exploration/networks.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdownload\u001b[39;00m \u001b[39mimport\u001b[39;00m download, default_checkpoints\n\u001b[1;32m     10\u001b[0m NORMS \u001b[39m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mlayer\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mLayerNorm,\n\u001b[1;32m     12\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mBatchNorm1d,\n\u001b[1;32m     13\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mIdentity\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m ACT \u001b[39m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgelu\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mGELU(),\n\u001b[1;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mReLU()\n\u001b[1;32m     19\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from networks import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m get_model(architecture\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mB_12-Wi_1024\u001b[39m\u001b[39m'\u001b[39m, resolution\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,  checkpoint\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39min21k_cifar10\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(architecture='B_12-Wi_1024', resolution=64, num_classes=10,  checkpoint='in21k_cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNoiseDataset(Dataset):\n",
    "    def __init__(self, num_images, image_size):\n",
    "        self.num_images = num_images\n",
    "        self.image_size = image_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Create a random noise image\n",
    "        image = np.random.rand(self.image_size[0], self.image_size[1], 3)\n",
    "        # Convert the numpy array to a PyTorch tensor\n",
    "        image = torch.from_numpy(image).float()\n",
    "        # Permute the tensor to have the channel as the first dimension\n",
    "        image = image.permute(2, 0, 1)\n",
    "        # Set requires_grad to True\n",
    "        image.requires_grad_(True)\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset = RandomNoiseDataset(num_images=1000, image_size= (64, 64))\n",
    "\n",
    "# Create the data loader\n",
    "data_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Now you can iterate over the data_loader to get batches of random noise images\n",
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize an image from the data loader\n",
    "def visualize_random_noise_image(data_loader):\n",
    "    # Get a batch of images\n",
    "    images = next(iter(data_loader))\n",
    "    # Take the first image from the batch\n",
    "    image = images[0]\n",
    " # Detach the image from the computation graph and convert to numpy for visualization\n",
    "    image = image.detach().cpu().numpy()\n",
    "    # Permute the numpy array to have the channel as the last dimension\n",
    "    image = np.transpose(image, (1, 2, 0))\n",
    "    # Plot the image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off') # Turn off axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_random_noise_image(data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients_across_batches = []\n",
    "for images in data_loader:\n",
    "\n",
    "    # Create a new tensor with the same data but reshaped, ensuring it's a leaf\n",
    "    input = torch.tensor(images.clone().view(images.size(0), -1), requires_grad=True)\n",
    "    input_gradients = torch.zeros_like(input[0])\n",
    "\n",
    "    for i in range(1024):\n",
    "        #predictions = model.linear_in(input) \n",
    "        predictions = model(input)\n",
    "        loss = torch.sum(predictions[:,i])\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        input_gradients += torch.mean(input.grad, axis=0)**2\n",
    "\n",
    "        input.grad.zero_()\n",
    "    \n",
    "    gradients_across_batches = [input_gradients] \n",
    "\n",
    "\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_gradients = torch.stack(gradients_across_batches, dim=0) \n",
    "mean_gradient = torch.mean(stacked_gradients, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gradient=np.array(mean_gradient).reshape(3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel1=mean_gradient[0, :, :]\n",
    "channel2=mean_gradient[1, :, :]\n",
    "channel3=mean_gradient[2, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.sqrt(channel3), cmap='magma', vmin=0)\n",
    "plt.title('Norm of weights per pixel for channel 2 - all layers', size=11)\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachmann_venv39",
   "language": "python",
   "name": "bachmann_venv39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
